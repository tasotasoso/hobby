{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parameters\n",
    "batch_size = 128\n",
    "epochs =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Datasets\n",
    "dataset, info = tfds.load('mnist', with_info=True, as_supervised=True)\n",
    "mnist_train, mnist_test = dataset['train'], dataset['test']\n",
    "\n",
    "def convert_types(image, label):\n",
    "    '''\n",
    "    normarize image matrix, and reshape. (28, 29) -> (784,)\n",
    "    '''\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return tf.reshape(image,[784,]), label\n",
    "\n",
    "mnist_train = mnist_train.map(convert_types).batch(batch_size)\n",
    "mnist_test = mnist_test.map(convert_types).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d1 = Dense(units=64, activation='relu')\n",
    "        self.d2 = Dense(units=64, activation='relu')\n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        z = self.d2(x)\n",
    "        return z\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d3 = Dense(units=64, activation='relu')\n",
    "        self.d4 = Dense(units=784, activation='sigmoid')\n",
    "    def call(self, z):\n",
    "        x = self.d3(z)\n",
    "        x = self.d4(x)\n",
    "        return x\n",
    "\n",
    "class Autoencorder(Model):\n",
    "    def __init__(self):\n",
    "        super(Autoencorder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def call(self, x):\n",
    "        z = self.encoder(x)\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed\n",
    "\n",
    "model = Autoencorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Setting for optimize\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define train & test\n",
    "@tf.function\n",
    "def train_step(image):\n",
    "     with tf.GradientTape() as tape:\n",
    "        predictions = model(image)\n",
    "        loss = tf.reduce_mean(tf.square(tf.subtract(predictions, image)))\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        train_loss(loss)\n",
    "        \n",
    "@tf.function\n",
    "def test_step(image):\n",
    "    predictions = model(image)\n",
    "    t_loss = tf.reduce_mean(tf.square(tf.subtract(predictions, image)))  \n",
    "    test_loss(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Do train & test\n",
    "for epoch in range(epochs):\n",
    "    for image, _ in mnist_train:\n",
    "        train_step(image)\n",
    "  \n",
    "    for test_image, _ in mnist_test:\n",
    "        test_step(test_image)\n",
    "  \n",
    "    template = 'Epoch {}, Loss: {}, Test Loss: {}'\n",
    "    print (template.format(epoch+1,\n",
    "                           train_loss.result(), \n",
    "                           test_loss.result()\n",
    "           )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test image\n",
    "test_image = [test_image for test_image, _ in mnist_test]\n",
    "plt.imshow(np.array(test_image[0][0]).reshape(28, 28))\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Decorded Test image\n",
    "decorded_images = model(test_image[0])\n",
    "decorded_images[0]\n",
    "plt.imshow(np.array(decorded_images[0]).reshape(28, 28))\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save model\n",
    "# refered  https://www.tensorflow.org/guide/saved_model\n",
    "tf.saved_model.save(model, \"./\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
